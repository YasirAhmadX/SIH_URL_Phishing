{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-02T04:17:44.969788Z","iopub.execute_input":"2023-10-02T04:17:44.970478Z","iopub.status.idle":"2023-10-02T04:17:45.427756Z","shell.execute_reply.started":"2023-10-02T04:17:44.970435Z","shell.execute_reply":"2023-10-02T04:17:45.426899Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/training-dataset/newdataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/training-dataset/newdataset.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:17:47.994907Z","iopub.execute_input":"2023-10-02T04:17:47.995497Z","iopub.status.idle":"2023-10-02T04:17:48.208255Z","shell.execute_reply.started":"2023-10-02T04:17:47.995457Z","shell.execute_reply":"2023-10-02T04:17:48.206916Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train.head","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:17:50.948939Z","iopub.execute_input":"2023-10-02T04:17:50.949945Z","iopub.status.idle":"2023-10-02T04:17:50.976345Z","shell.execute_reply.started":"2023-10-02T04:17:50.949899Z","shell.execute_reply":"2023-10-02T04:17:50.975207Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<bound method NDFrame.head of        length_url  domain_length  domain_in_ip  server_client_domain  \\\n0              25             17             0                     0   \n1             223             16             0                     0   \n2              15             14             0                     0   \n3              81             19             0                     0   \n4              19             19             0                     0   \n...           ...            ...           ...                   ...   \n88642          23             23             0                     0   \n88643          34             34             0                     0   \n88644          70             22             0                     0   \n88645          28             27             0                     0   \n88646          16             16             0                     0   \n\n       directory_length  file_length  params_length  tld_present_params  \\\n0                     8            7             -1                  -1   \n1                    42            9            165                   0   \n2                     1            0             -1                  -1   \n3                    62            9             -1                  -1   \n4                    -1           -1             -1                  -1   \n...                 ...          ...            ...                 ...   \n88642                -1           -1             -1                  -1   \n88643                -1           -1             -1                  -1   \n88644                48           11             -1                  -1   \n88645                 1            0             -1                  -1   \n88646                -1           -1             -1                  -1   \n\n       email_in_url  time_response  asn_ip  time_domain_activation  \\\n0                 0              0   60781                      -1   \n1                 0              0   36024                     579   \n2                 0              0    4766                      -1   \n3                 0              0   20454                      -1   \n4                 0              0   53831                    6998   \n...             ...            ...     ...                     ...   \n88642             0              0    8560                    5509   \n88643             0              0   26496                    5046   \n88644             0              0  394695                    1844   \n88645             0              0   47583                      -1   \n88646             0              0   47846                     300   \n\n       time_domain_expiration  domain_google_index  url_shortened  phishing  \\\n0                          -1                    0              0         1   \n1                         150                    0              0         1   \n2                          -1                    0              0         0   \n3                          -1                    0              0         1   \n4                         306                    0              0         0   \n...                       ...                  ...            ...       ...   \n88642                     334                    0              0         0   \n88643                     431                    0              0         0   \n88644                     712                    0              0         1   \n88645                      -1                    0              0         1   \n88646                      64                    0              0         0   \n\n       qty_char_domain  \n0                    6  \n1                    7  \n2                    5  \n3                    9  \n4                    7  \n...                ...  \n88642                9  \n88643               16  \n88644                7  \n88645                7  \n88646                6  \n\n[88647 rows x 17 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"train = train.drop('time_domain_expiration', axis=1)\ntrain = train.drop('time_domain_activation', axis=1)\ntrain = train.drop('directory_length',axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:17:51.899150Z","iopub.execute_input":"2023-10-02T04:17:51.899596Z","iopub.status.idle":"2023-10-02T04:17:51.945680Z","shell.execute_reply.started":"2023-10-02T04:17:51.899560Z","shell.execute_reply":"2023-10-02T04:17:51.944694Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:17:52.725495Z","iopub.execute_input":"2023-10-02T04:17:52.726188Z","iopub.status.idle":"2023-10-02T04:17:52.731257Z","shell.execute_reply.started":"2023-10-02T04:17:52.726153Z","shell.execute_reply":"2023-10-02T04:17:52.730490Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['length_url', 'domain_length', 'domain_in_ip', 'server_client_domain',\n       'file_length', 'params_length', 'tld_present_params', 'email_in_url',\n       'time_response', 'asn_ip', 'domain_google_index', 'url_shortened',\n       'phishing', 'qty_char_domain'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"#Splitting Datasets\ndata = train.drop('phishing', axis=1)\nlabel = train['phishing']","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:17:53.579194Z","iopub.execute_input":"2023-10-02T04:17:53.579848Z","iopub.status.idle":"2023-10-02T04:17:53.595560Z","shell.execute_reply.started":"2023-10-02T04:17:53.579810Z","shell.execute_reply":"2023-10-02T04:17:53.594293Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#finding euclidian distance\n'''def calculate_euclidean_distances(dataset, real_time_url_features):\n    euclidean_distances = np.linalg.norm(newdata.iloc[:, :-1].values - real_time_url_features, axis=1)\n    return euclidean_distances'''\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:17:54.138649Z","iopub.execute_input":"2023-10-02T04:17:54.139127Z","iopub.status.idle":"2023-10-02T04:17:54.146377Z","shell.execute_reply.started":"2023-10-02T04:17:54.139063Z","shell.execute_reply":"2023-10-02T04:17:54.145127Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'def calculate_euclidean_distances(dataset, real_time_url_features):\\n    euclidean_distances = np.linalg.norm(newdata.iloc[:, :-1].values - real_time_url_features, axis=1)\\n    return euclidean_distances'"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(data,label,test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:17:55.020933Z","iopub.execute_input":"2023-10-02T04:17:55.021391Z","iopub.status.idle":"2023-10-02T04:17:55.737512Z","shell.execute_reply.started":"2023-10-02T04:17:55.021354Z","shell.execute_reply":"2023-10-02T04:17:55.736015Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def display_test_scores(test, pred):\n    str_out = \"\"\n    str_out += (\"TEST SCORES\")\n    str_out += (\"\\n\")\n\n    #print accuracy\n    accuracy = accuracy_score(test, pred)\n    str_out += (\"ACCURACY: {:.4f}\\n\".format(accuracy))\n    str_out += (\"\\n\")\n\n    #print AUC score\n    auc = roc_auc_score(test, pred)\n    str_out += (\"AUC: {:.4f}\\n\".format(auc))\n    str_out += (\"\\n\")\n\n    #print confusion matrix\n    str_out += (\"CONFUSION MATRIX:\\n\")\n    conf_mat = confusion_matrix(test, pred)\n    str_out += (\"{}\".format(conf_mat))\n    str_out += (\"\\n\")\n    str_out += (\"\\n\")\n\n    #print FP, FN\n    str_out += (\"FALSE POSITIVES:\\n\")\n    fp = conf_mat[1][0]\n    pos_labels = conf_mat[1][0]+conf_mat[1][1]\n    str_out += (\"{} out of {} positive labels ({:.4f}%)\\n\".format(fp, pos_labels,fp/pos_labels))\n    str_out += (\"\\n\")\n\n    str_out += (\"FALSE NEGATIVES:\\n\")\n    fn = conf_mat[0][1]\n    neg_labels = conf_mat[0][1]+conf_mat[0][0]\n    str_out += (\"{} out of {} negative labels ({:.4f}%)\\n\".format(fn, neg_labels, fn/neg_labels))\n    str_out += (\"\\n\")\n\n    #print classification report\n    str_out += (\"PRECISION, RECALL, F1 scores:\\n\")\n    str_out += (\"{}\".format(classification_report(test, pred)))\n    \n    false_indexes = np.where(test != pred)\n    return str_out, false_indexes","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:17:55.797862Z","iopub.execute_input":"2023-10-02T04:17:55.799114Z","iopub.status.idle":"2023-10-02T04:17:55.807085Z","shell.execute_reply.started":"2023-10-02T04:17:55.799054Z","shell.execute_reply":"2023-10-02T04:17:55.806194Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nimport pickle as pic\nfrom sklearn.metrics import accuracy_score, roc_curve, confusion_matrix, classification_report, roc_auc_score\nknn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train, y_train)\npic.dump(knn,open('knn.pkl','wb'))\nprediction = knn.predict(X_val)\nresults,false = display_test_scores(y_val, prediction)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:18:00.108319Z","iopub.execute_input":"2023-10-02T04:18:00.108982Z","iopub.status.idle":"2023-10-02T04:18:02.537658Z","shell.execute_reply.started":"2023-10-02T04:18:00.108950Z","shell.execute_reply":"2023-10-02T04:18:02.536779Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"TEST SCORES\nACCURACY: 0.9201\n\nAUC: 0.8947\n\nCONFUSION MATRIX:\n[[17029   420]\n [ 1706  7440]]\n\nFALSE POSITIVES:\n1706 out of 9146 positive labels (0.1865%)\n\nFALSE NEGATIVES:\n420 out of 17449 negative labels (0.0241%)\n\nPRECISION, RECALL, F1 scores:\n              precision    recall  f1-score   support\n\n           0       0.91      0.98      0.94     17449\n           1       0.95      0.81      0.87      9146\n\n    accuracy                           0.92     26595\n   macro avg       0.93      0.89      0.91     26595\nweighted avg       0.92      0.92      0.92     26595\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ny_train_pred = knn.predict(X_train)\nmse_train = mean_squared_error(y_train, y_train_pred)\nmse_val = mean_squared_error(y_val, prediction)\n\nbias = mse_train\nvariance = mse_val - mse_train\n\nprint(\"Bias (Training MSE):\", bias)\nprint(\"Variance:\", variance)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:18:12.031882Z","iopub.execute_input":"2023-10-02T04:18:12.032865Z","iopub.status.idle":"2023-10-02T04:18:16.075385Z","shell.execute_reply.started":"2023-10-02T04:18:12.032825Z","shell.execute_reply":"2023-10-02T04:18:16.074178Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Bias (Training MSE): 0.042416038161541936\nVariance: 0.03752380015393089\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nNN = MLPClassifier()\nNN.fit(X_train,y_train)\nprediction = NN.predict(X_val)\nresults,false = display_test_scores(y_val, prediction)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T04:19:37.038118Z","iopub.execute_input":"2023-10-02T04:19:37.038585Z","iopub.status.idle":"2023-10-02T04:19:56.970296Z","shell.execute_reply.started":"2023-10-02T04:19:37.038506Z","shell.execute_reply":"2023-10-02T04:19:56.968841Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"TEST SCORES\nACCURACY: 0.7620\n\nAUC: 0.6600\n\nCONFUSION MATRIX:\n[[17217   232]\n [ 6098  3048]]\n\nFALSE POSITIVES:\n6098 out of 9146 positive labels (0.6667%)\n\nFALSE NEGATIVES:\n232 out of 17449 negative labels (0.0133%)\n\nPRECISION, RECALL, F1 scores:\n              precision    recall  f1-score   support\n\n           0       0.74      0.99      0.84     17449\n           1       0.93      0.33      0.49      9146\n\n    accuracy                           0.76     26595\n   macro avg       0.83      0.66      0.67     26595\nweighted avg       0.80      0.76      0.72     26595\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Dense\nmodel = keras.Sequential([\n    keras.layers.Dense(64, activation='relu',input_shape=(13,) ),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, epochs=200, batch_size=32)\nval_loss, val_accuracy = model.evaluate(X_val, y_val)\nprint(f\"Validation accuracy: {val_accuracy * 100:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:07:43.370604Z","iopub.execute_input":"2023-10-02T05:07:43.372402Z","iopub.status.idle":"2023-10-02T05:20:07.611255Z","shell.execute_reply.started":"2023-10-02T05:07:43.372336Z","shell.execute_reply":"2023-10-02T05:20:07.609876Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 1/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 52.8350 - accuracy: 0.6266\nEpoch 2/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 34.7305 - accuracy: 0.6787\nEpoch 3/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 20.5316 - accuracy: 0.7144\nEpoch 4/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 16.0716 - accuracy: 0.7315\nEpoch 5/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 12.5727 - accuracy: 0.7410\nEpoch 6/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 8.1386 - accuracy: 0.7486\nEpoch 7/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 5.7922 - accuracy: 0.7663\nEpoch 8/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 4.5581 - accuracy: 0.7652\nEpoch 9/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 2.5906 - accuracy: 0.7848\nEpoch 10/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 1.8290 - accuracy: 0.7832\nEpoch 11/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.8833 - accuracy: 0.8047\nEpoch 12/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.5168 - accuracy: 0.8200\nEpoch 13/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.4620 - accuracy: 0.8174\nEpoch 14/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.4564 - accuracy: 0.8174\nEpoch 15/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.4413 - accuracy: 0.8297\nEpoch 16/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.4273 - accuracy: 0.8361\nEpoch 17/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.4221 - accuracy: 0.8378\nEpoch 18/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.4069 - accuracy: 0.8444\nEpoch 19/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3971 - accuracy: 0.8511\nEpoch 20/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.4000 - accuracy: 0.8481\nEpoch 21/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3798 - accuracy: 0.8574\nEpoch 22/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3774 - accuracy: 0.8578\nEpoch 23/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3930 - accuracy: 0.8515\nEpoch 24/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3748 - accuracy: 0.8603\nEpoch 25/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3746 - accuracy: 0.8601\nEpoch 26/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3743 - accuracy: 0.8608\nEpoch 27/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3810 - accuracy: 0.8579\nEpoch 28/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3805 - accuracy: 0.8577\nEpoch 29/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3746 - accuracy: 0.8618\nEpoch 30/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3623 - accuracy: 0.8661\nEpoch 31/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3660 - accuracy: 0.8643\nEpoch 32/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3658 - accuracy: 0.8631\nEpoch 33/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3548 - accuracy: 0.8682\nEpoch 34/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3562 - accuracy: 0.8665\nEpoch 35/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3489 - accuracy: 0.8691\nEpoch 36/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3469 - accuracy: 0.8712\nEpoch 37/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3400 - accuracy: 0.8727\nEpoch 38/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3372 - accuracy: 0.8739\nEpoch 39/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3670 - accuracy: 0.8597\nEpoch 40/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3564 - accuracy: 0.8703\nEpoch 41/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3506 - accuracy: 0.8708\nEpoch 42/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3484 - accuracy: 0.8690\nEpoch 43/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3400 - accuracy: 0.8730\nEpoch 44/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3439 - accuracy: 0.8687\nEpoch 45/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3306 - accuracy: 0.8746\nEpoch 46/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3196 - accuracy: 0.8779\nEpoch 47/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3502 - accuracy: 0.8637\nEpoch 48/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3124 - accuracy: 0.8804\nEpoch 49/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3111 - accuracy: 0.8808\nEpoch 50/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3031 - accuracy: 0.8828\nEpoch 51/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3151 - accuracy: 0.8783\nEpoch 52/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3099 - accuracy: 0.8802\nEpoch 53/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3003 - accuracy: 0.8829\nEpoch 54/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2949 - accuracy: 0.8853\nEpoch 55/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3002 - accuracy: 0.8833\nEpoch 56/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3017 - accuracy: 0.8832\nEpoch 57/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2990 - accuracy: 0.8821\nEpoch 58/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2979 - accuracy: 0.8823\nEpoch 59/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2908 - accuracy: 0.8850\nEpoch 60/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2971 - accuracy: 0.8865\nEpoch 61/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2904 - accuracy: 0.8858\nEpoch 62/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2957 - accuracy: 0.8852\nEpoch 63/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2904 - accuracy: 0.8855\nEpoch 64/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2904 - accuracy: 0.8845\nEpoch 65/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2923 - accuracy: 0.8865\nEpoch 66/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2838 - accuracy: 0.8880\nEpoch 67/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2844 - accuracy: 0.8879\nEpoch 68/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3009 - accuracy: 0.8816\nEpoch 69/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2835 - accuracy: 0.8874\nEpoch 70/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2925 - accuracy: 0.8856\nEpoch 71/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2946 - accuracy: 0.8862\nEpoch 72/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2873 - accuracy: 0.8867\nEpoch 73/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2786 - accuracy: 0.8905\nEpoch 74/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2873 - accuracy: 0.8858\nEpoch 75/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2760 - accuracy: 0.8915\nEpoch 76/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2954 - accuracy: 0.8826\nEpoch 77/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2884 - accuracy: 0.8853\nEpoch 78/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2859 - accuracy: 0.8869\nEpoch 79/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2768 - accuracy: 0.8906\nEpoch 80/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2775 - accuracy: 0.8905\nEpoch 81/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2770 - accuracy: 0.8914\nEpoch 82/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2787 - accuracy: 0.8911\nEpoch 83/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2784 - accuracy: 0.8902\nEpoch 84/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2860 - accuracy: 0.8865\nEpoch 85/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2772 - accuracy: 0.8905\nEpoch 86/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.8906\nEpoch 87/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2761 - accuracy: 0.8910\nEpoch 88/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2834 - accuracy: 0.8875\nEpoch 89/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2777 - accuracy: 0.8891\nEpoch 90/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2746 - accuracy: 0.8912\nEpoch 91/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2776 - accuracy: 0.8901\nEpoch 92/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2766 - accuracy: 0.8916\nEpoch 93/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2746 - accuracy: 0.8907\nEpoch 94/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2725 - accuracy: 0.8931\nEpoch 95/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2771 - accuracy: 0.8895\nEpoch 96/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2795 - accuracy: 0.8892\nEpoch 97/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2739 - accuracy: 0.8915\nEpoch 98/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2785 - accuracy: 0.8901\nEpoch 99/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2732 - accuracy: 0.8909\nEpoch 100/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2748 - accuracy: 0.8913\nEpoch 101/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2719 - accuracy: 0.8933\nEpoch 102/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2734 - accuracy: 0.8910\nEpoch 103/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2895 - accuracy: 0.8875\nEpoch 104/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2819 - accuracy: 0.8899\nEpoch 105/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2740 - accuracy: 0.8925\nEpoch 106/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2736 - accuracy: 0.8921\nEpoch 107/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2699 - accuracy: 0.8928\nEpoch 108/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2732 - accuracy: 0.8915\nEpoch 109/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2726 - accuracy: 0.8927\nEpoch 110/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2713 - accuracy: 0.8919\nEpoch 111/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2700 - accuracy: 0.8929\nEpoch 112/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2760 - accuracy: 0.8909\nEpoch 113/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2701 - accuracy: 0.8939\nEpoch 114/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2746 - accuracy: 0.8916\nEpoch 115/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2749 - accuracy: 0.8899\nEpoch 116/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2694 - accuracy: 0.8929\nEpoch 117/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2712 - accuracy: 0.8920\nEpoch 118/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2719 - accuracy: 0.8927\nEpoch 119/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2685 - accuracy: 0.8943\nEpoch 120/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2719 - accuracy: 0.8919\nEpoch 121/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2699 - accuracy: 0.8930\nEpoch 122/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.3719 - accuracy: 0.8637\nEpoch 123/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.4031 - accuracy: 0.8466\nEpoch 124/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.3281 - accuracy: 0.8716\nEpoch 125/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2812 - accuracy: 0.8854\nEpoch 126/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2784 - accuracy: 0.8864\nEpoch 127/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2752 - accuracy: 0.8895\nEpoch 128/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2717 - accuracy: 0.8892\nEpoch 129/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2752 - accuracy: 0.8893\nEpoch 130/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2690 - accuracy: 0.8917\nEpoch 131/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2683 - accuracy: 0.8928\nEpoch 132/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2687 - accuracy: 0.8927\nEpoch 133/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2682 - accuracy: 0.8930\nEpoch 134/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2701 - accuracy: 0.8930\nEpoch 135/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2678 - accuracy: 0.8923\nEpoch 136/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2692 - accuracy: 0.8934\nEpoch 137/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2686 - accuracy: 0.8924\nEpoch 138/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2733 - accuracy: 0.8919\nEpoch 139/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2668 - accuracy: 0.8938\nEpoch 140/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2666 - accuracy: 0.8933\nEpoch 141/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2664 - accuracy: 0.8939\nEpoch 142/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2699 - accuracy: 0.8923\nEpoch 143/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2652 - accuracy: 0.8944\nEpoch 144/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2722 - accuracy: 0.8939\nEpoch 145/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2658 - accuracy: 0.8936\nEpoch 146/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2662 - accuracy: 0.8949\nEpoch 147/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2681 - accuracy: 0.8927\nEpoch 148/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2695 - accuracy: 0.8931\nEpoch 149/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2653 - accuracy: 0.8936\nEpoch 150/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2636 - accuracy: 0.8955\nEpoch 151/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2655 - accuracy: 0.8946\nEpoch 152/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2659 - accuracy: 0.8942\nEpoch 153/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2669 - accuracy: 0.8934\nEpoch 154/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2762 - accuracy: 0.8899\nEpoch 155/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2668 - accuracy: 0.8934\nEpoch 156/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2651 - accuracy: 0.8939\nEpoch 157/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2672 - accuracy: 0.8947\nEpoch 158/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2630 - accuracy: 0.8943\nEpoch 159/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2668 - accuracy: 0.8931\nEpoch 160/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2673 - accuracy: 0.8933\nEpoch 161/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2626 - accuracy: 0.8946\nEpoch 162/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2648 - accuracy: 0.8942\nEpoch 163/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2707 - accuracy: 0.8915\nEpoch 164/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2715 - accuracy: 0.8934\nEpoch 165/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2631 - accuracy: 0.8947\nEpoch 166/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2640 - accuracy: 0.8947\nEpoch 167/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2625 - accuracy: 0.8950\nEpoch 168/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2659 - accuracy: 0.8940\nEpoch 169/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2633 - accuracy: 0.8950\nEpoch 170/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2619 - accuracy: 0.8951\nEpoch 171/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2620 - accuracy: 0.8939\nEpoch 172/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2845 - accuracy: 0.8865\nEpoch 173/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2628 - accuracy: 0.8954\nEpoch 174/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2616 - accuracy: 0.8960\nEpoch 175/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2649 - accuracy: 0.8935\nEpoch 176/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2615 - accuracy: 0.8943\nEpoch 177/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2657 - accuracy: 0.8938\nEpoch 178/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2632 - accuracy: 0.8954\nEpoch 179/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2644 - accuracy: 0.8935\nEpoch 180/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2628 - accuracy: 0.8945\nEpoch 181/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2637 - accuracy: 0.8943\nEpoch 182/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2629 - accuracy: 0.8942\nEpoch 183/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2652 - accuracy: 0.8948\nEpoch 184/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2600 - accuracy: 0.8960\nEpoch 185/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2630 - accuracy: 0.8949\nEpoch 186/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2660 - accuracy: 0.8950\nEpoch 187/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2632 - accuracy: 0.8948\nEpoch 188/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2623 - accuracy: 0.8953\nEpoch 189/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2624 - accuracy: 0.8946\nEpoch 190/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2604 - accuracy: 0.8951\nEpoch 191/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2614 - accuracy: 0.8951\nEpoch 192/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2646 - accuracy: 0.8936\nEpoch 193/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2641 - accuracy: 0.8936\nEpoch 194/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2613 - accuracy: 0.8950\nEpoch 195/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2735 - accuracy: 0.8937\nEpoch 196/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2601 - accuracy: 0.8955\nEpoch 197/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2615 - accuracy: 0.8953\nEpoch 198/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2611 - accuracy: 0.8955\nEpoch 199/200\n1940/1940 [==============================] - 3s 2ms/step - loss: 0.2620 - accuracy: 0.8959\nEpoch 200/200\n1940/1940 [==============================] - 4s 2ms/step - loss: 0.2590 - accuracy: 0.8953\n832/832 [==============================] - 1s 1ms/step - loss: 0.2678 - accuracy: 0.8936\nValidation accuracy: 89.36%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}